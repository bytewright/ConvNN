net: "/home/ellerch/caffeProject/jobs/job1/deploy_alexnet_places365.prototxt"
snapshot_prefix: "/home/ellerch/caffeProject/auto_trainer_output/tmp/job1/"
snapshot: 20000
solver_mode: GPU

# test_iter specifies how many forward passes the test should carry out.
# In the case of MNIST, we have test batch size 100 and 100 test iterations,
# covering the full 10,000 testing images.
# how many mini-batches to test in each validation phase
test_iter: 100

# Carry out testing every 500 training iterations.
test_interval: 500

# The base learning rate, momentum and the weight decay of the network.
# begin training at a learning rate of 0.01 = 1e-2
base_lr: 0.01

# factor for gradiant correction based on previous gradiants
momentum: 0.9
weight_decay: 0.0005

# drop the learning rate by a factor of 10
# (i.e., multiply it by a factor of gamma = 0.1)
gamma: 0.5

# learning rate policy: drop the learning rate in "steps"
# by a factor of gamma every stepsize iterations
lr_policy: "step"
stepsize: 10000          # drop the learning rate every 100K iterations

display: 500           # how often do we print training loss
max_iter: 150000          # The maximum number of iterations

