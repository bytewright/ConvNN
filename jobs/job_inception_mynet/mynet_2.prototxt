name: "CaffeNet-Places365"
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/ellerch/db/places365/places365CNN_mean.binaryproto"
  }
  data_param {
    source: "/home/ellerch/db/places365/train_lmdb"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/home/ellerch/db/places365/places365CNN_mean.binaryproto"
  }
  data_param {
    source: "/home/ellerch/db/places365/val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
#------------------------------ layer 1
# shape: [128,3,227,227]
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 7
    pad: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
#------------------------------ layer 2
# shape: [256 96 112 112]
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    pad: 0
    kernel_size: 3
    stride: 2
  }
}
# shape: [256 96 55 55]
#------------------------------ layer 2 inception
layer {
  name: "inception1_conv1_1x1"
  type: "Convolution"
  bottom: "conv1"
  top: "inception1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "xavier"
      #std: "VarianceNorm_AVERAGE"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
# shape@concat: [256, 256, 28, 28]
layer {
  name: "inception1_conv2_3x3"
  type: "Convolution"
  bottom: "conv1"
  top: "inception1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      #std: "VarianceNorm_AVERAGE"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
# shape@concat: [256, 256, 28, 28]
layer {
  name: "inception1_conv3_5x5"
  type: "Convolution"
  bottom: "conv1"
  top: "inception1_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    stride: 2
    weight_filler {
      type: "xavier"
      #std: "VarianceNorm_AVERAGE"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
# shape@concat: [256, 256, 28, 28]
layer {
  name: "inception1_pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "inception1_pool1"
  pooling_param {
    pool: MAX
    pad: 0
    kernel_size: 3
    stride: 2
  }
}
# shape@concat: [256, 256, 28, 28]
layer {
  name: "inception1_ch_concat"
  type: "Concat"
  bottom: "inception1_conv1"
  bottom: "inception1_conv2"
  bottom: "inception1_conv3"
  bottom: "inception1_pool1"
  top: "concat1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "concat_relu1"
  type: "ReLU"
  bottom: "concat1"
  top: "concat1"
}
# shape@concat: [256 864 28 28]
#----------------------------------layer 3
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "concat1"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
# shape: [256 864 14 14]
#----------------------------------layer 4
# -------------------------- start inception module --------------------------
layer {
  name: "inception2_conv1_1x1"
  type: "Convolution"
  bottom: "pool2"
  top: "inception2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "xavier"
      #std: "VarianceNorm_AVERAGE"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
# shape@concat: [256, 128, 7, 7]
layer {
  name: "inception2_conv2_1x1"
  type: "Convolution"
  bottom: "pool2"
  top: "inception2_conv2_1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      #std: "VarianceNorm_AVERAGE"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "inception2_conv2_3x3"
  type: "Convolution"
  bottom: "inception2_conv2_1x1"
  top: "inception2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      #std: "VarianceNorm_AVERAGE"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
# shape@concat: [256, 128, 7, 7]
layer {
  name: "inception2_conv3_1x1"
  type: "Convolution"
  bottom: "pool2"
  top: "inception2_conv3_1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      #std: "VarianceNorm_AVERAGE"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "inception2_conv3_5x5"
  type: "Convolution"
  bottom: "inception2_conv3_1x1"
  top: "inception2_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    stride: 2
    weight_filler {
      type: "xavier"
      #std: "VarianceNorm_AVERAGE"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
# shape@concat: [256, 128, 7, 7]
layer {
  name: "inception2_pool1"
  type: "Pooling"
  bottom: "pool2"
  top: "inception2_pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
# shape@concat: [256, 128, 7, 7]
layer {
  name: "inception2_pool1_1x1"
  type: "Convolution"
  bottom: "inception2_pool1"
  top: "inception2_pool1_1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
# shape@concat: [256, 128, 7, 7]
layer {
  name: "inception2_ch_concat"
  type: "Concat"
  bottom: "inception2_conv1"
  bottom: "inception2_conv2"
  bottom: "inception2_conv3"
  bottom: "inception2_pool1_1x1"
  top: "concat2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "concat_relu2"
  type: "ReLU"
  bottom: "concat2"
  top: "concat2"
}
layer {
  name: "drop_inception2"
  type: "Dropout"
  bottom: "concat2"
  top: "concat2"
  dropout_param {
    dropout_ratio: 0.1
  }
}
# shape: [256, 512, 7, 7]
# --------------------------- end inception module ---------------------------
#----------------------------------layer 5
# -------------------------- start inception module --------------------------
layer {
  name: "inception3_conv1_1x1"
  type: "Convolution"
  bottom: "concat2"
  top: "inception3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "xavier"
      #std: "VarianceNorm_AVERAGE"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
# shape@concat: [256, 256, 7, 7]
layer {
  name: "inception3_conv2_1x1"
  type: "Convolution"
  bottom: "concat2"
  top: "inception3_conv2_1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      #std: "VarianceNorm_AVERAGE"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "inception3_conv2_3x3"
  type: "Convolution"
  bottom: "inception3_conv2_1x1"
  top: "inception3_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      #std: "VarianceNorm_AVERAGE"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
# shape@concat: [256, 128, 7, 7]
layer {
  name: "inception3_conv3_1x1"
  type: "Convolution"
  bottom: "concat2"
  top: "inception3_conv3_1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      #std: "VarianceNorm_AVERAGE"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "inception3_conv3_5x5"
  type: "Convolution"
  bottom: "inception3_conv3_1x1"
  top: "inception3_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 2
    weight_filler {
      type: "xavier"
      #std: "VarianceNorm_AVERAGE"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
# shape@concat: [256, 32, 7, 7]
layer {
  name: "inception3_pool1"
  type: "Pooling"
  bottom: "concat2"
  top: "inception3_pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
# shape@concat: [256, 128, 7, 7]
layer {
  name: "inception3_pool1_1x1"
  type: "Convolution"
  bottom: "inception3_pool1"
  top: "inception3_pool1_1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
# shape@concat: [256, 128, 7, 7]
layer {
  name: "inception3_ch_concat"
  type: "Concat"
  bottom: "inception3_conv1"
  bottom: "inception3_conv2"
  bottom: "inception3_conv3"
  bottom: "inception3_pool1_1x1"
  top: "concat3"
  concat_param {
    axis: 1
  }
}
layer {
  name: "concat_relu3"
  type: "ReLU"
  bottom: "concat3"
  top: "concat3"
}
layer {
  name: "drop_inception3"
  type: "Dropout"
  bottom: "concat3"
  top: "concat3"
  dropout_param {
    dropout_ratio: 0.1
  }
}
# shape: [256, 512, 7, 7]
# --------------------------- end inception module ---------------------------
#----------------------------------layer 6
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "concat3"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
# shape: [256, 4096]
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
# shape: [256, 4096]
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 365
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
# shape: [256, 365]
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy_top_5"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy_top_5"
  accuracy_param {
    top_k: 5
  }
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
